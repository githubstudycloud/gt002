# è‡ªå®šä¹‰å¼€æºæ¨¡å‹æ¥å…¥æŒ‡å—

æœ¬æŒ‡å—è¯´æ˜å¦‚ä½•å°†è‡ªéƒ¨ç½²çš„å¼€æºå¤§æ¨¡å‹é…ç½®åˆ°Claude Relay Serviceä¸­ä½œä¸ºä»£ç†æœåŠ¡ç«¯ã€‚

## ğŸ¯ é€‚ç”¨åœºæ™¯

æ‚¨å·²ç»éƒ¨ç½²äº†ä»¥ä¸‹å¼€æºæ¨¡å‹å¹¶å¸Œæœ›é€šè¿‡Claude Relay Serviceç»Ÿä¸€ç®¡ç†:
- Qwen3-VL-235B-A22B-Instruct-FP8
- Qwen3-32B
- Qwen3-235B-A22B
- GLM-4.6-FP8
- Qwen3-Coder-480B-A35B

## ğŸ“‹ å‰ææ¡ä»¶

### 1. æ¨¡å‹æœåŠ¡ç«¯è¦æ±‚

æ‚¨çš„å¼€æºæ¨¡å‹éœ€è¦é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€æä¾›OpenAIå…¼å®¹çš„APIæ¥å£:

**æ¨èæ–¹æ¡ˆ:**
- **vLLM** - é«˜æ€§èƒ½æ¨ç†å¼•æ“,åŸç”Ÿæ”¯æŒOpenAI APIæ ¼å¼
- **FastChat** - æ”¯æŒå¤šç§æ¨¡å‹çš„APIæœåŠ¡å™¨
- **Text-Generation-Inference** (TGI) - Hugging Faceçš„æ¨ç†æœåŠ¡å™¨
- **Ollama** - æœ¬åœ°æ¨¡å‹è¿è¡Œå·¥å…·

### 2. APIç«¯ç‚¹æ ¼å¼

ç¡®ä¿æ‚¨çš„æ¨¡å‹æœåŠ¡æä¾›ä»¥ä¸‹OpenAIå…¼å®¹ç«¯ç‚¹:
```
POST http://your-server:port/v1/chat/completions
```

## ğŸš€ æ–¹æ³•ä¸€: ä½¿ç”¨Azure OpenAIè´¦æˆ·ç±»å‹(æ¨è)

Claude Relay Serviceçš„Azure OpenAIè´¦æˆ·ç±»å‹æ”¯æŒè‡ªå®šä¹‰endpoint,å¯ä»¥ç”¨æ¥æ¥å…¥ä»»ä½•OpenAIå…¼å®¹çš„APIã€‚

### æ­¥éª¤ 1: å‡†å¤‡æ¨¡å‹APIç«¯ç‚¹

å‡è®¾æ‚¨ä½¿ç”¨vLLMéƒ¨ç½²äº†Qwen3-32Bæ¨¡å‹:

```bash
# å¯åŠ¨vLLMæœåŠ¡ (ç¤ºä¾‹)
python -m vllm.entrypoints.openai.api_server \
  --model Qwen/Qwen3-32B \
  --host 0.0.0.0 \
  --port 8000 \
  --served-model-name qwen3-32b
```

APIç«¯ç‚¹: `http://your-server-ip:8000`

### æ­¥éª¤ 2: ä¿®æ”¹Azure endpointæ ¼å¼éªŒè¯

ç”±äºClaude Relay Serviceé»˜è®¤éªŒè¯Azure endpointæ ¼å¼ä¸º `https://*.openai.azure.com`,æˆ‘ä»¬éœ€è¦ä¿®æ”¹éªŒè¯é€»è¾‘ä»¥æ”¯æŒè‡ªå®šä¹‰åŸŸåã€‚

**ä¿®æ”¹æ–‡ä»¶:** `src/routes/admin.js` (ç¬¬8010-8017è¡Œ)

**åŸä»£ç :**
```javascript
// éªŒè¯ Azure endpoint æ ¼å¼
if (!azureEndpoint.match(/^https:\/\/[\w-]+\.openai\.azure\.com$/)) {
  return res.status(400).json({
    success: false,
    message:
      'Invalid Azure OpenAI endpoint format. Expected: https://your-resource.openai.azure.com'
  })
}
```

**ä¿®æ”¹ä¸º:**
```javascript
// éªŒè¯ Azure endpoint æ ¼å¼ - æ”¯æŒè‡ªå®šä¹‰åŸŸå
if (!azureEndpoint.match(/^https?:\/\/.+/) && !azureEndpoint.match(/^http:\/\/[\d.]+:\d+$/)) {
  return res.status(400).json({
    success: false,
    message:
      'Invalid endpoint format. Expected: http://ip:port or https://domain'
  })
}
```

### æ­¥éª¤ 3: é€šè¿‡Webç•Œé¢æ·»åŠ è´¦æˆ·

1. è®¿é—®Claude Relay Serviceç®¡ç†ç•Œé¢: `http://localhost:3000/admin-next`

2. ç™»å½•å,è¿›å…¥ **è´¦æˆ·ç®¡ç†** > **Azure OpenAI è´¦æˆ·**

3. ç‚¹å‡» **æ·»åŠ è´¦æˆ·**,å¡«å†™ä»¥ä¸‹ä¿¡æ¯:

```json
{
  "name": "Qwen3-32B",
  "description": "è‡ªéƒ¨ç½²çš„Qwen3-32Bæ¨¡å‹",
  "accountType": "shared",
  "azureEndpoint": "http://192.168.1.100:8000",
  "apiVersion": "2024-02-01",
  "deploymentName": "qwen3-32b",
  "apiKey": "sk-dummy-key-not-required",
  "supportedModels": ["qwen3-32b", "claude-3-opus-20240229"],
  "priority": 50,
  "isActive": true,
  "schedulable": true
}
```

**å­—æ®µè¯´æ˜:**
- `azureEndpoint`: æ‚¨çš„æ¨¡å‹æœåŠ¡åœ°å€
- `deploymentName`: vLLMçš„ `--served-model-name` å‚æ•°å€¼
- `apiKey`: å¦‚æœæ‚¨çš„æœåŠ¡ä¸éœ€è¦è®¤è¯,å¡«å†™ä»»æ„å€¼
- `supportedModels`: æ˜ å°„åˆ°Claudeæ¨¡å‹åç§°,å®¢æˆ·ç«¯è¯·æ±‚æ—¶ä½¿ç”¨

### æ­¥éª¤ 4: æµ‹è¯•è¿æ¥

æ·»åŠ è´¦æˆ·å,ç³»ç»Ÿä¼šè‡ªåŠ¨æµ‹è¯•è¿æ¥ã€‚æ‚¨ä¹Ÿå¯ä»¥æ‰‹åŠ¨æµ‹è¯•:

```bash
curl -X POST http://localhost:3000/v1/messages \
  -H "Content-Type: application/json" \
  -H "x-api-key: your-relay-api-key" \
  -d '{
    "model": "claude-3-opus-20240229",
    "messages": [
      {"role": "user", "content": "ä½ å¥½"}
    ],
    "max_tokens": 1024
  }'
```

## ğŸ”§ æ–¹æ³•äºŒ: ä½¿ç”¨OpenAIè´¦æˆ·ç±»å‹

å¦‚æœæ‚¨çš„æ¨¡å‹æœåŠ¡å®Œå…¨å…¼å®¹OpenAI APIæ ¼å¼,å¯ä»¥ç›´æ¥ä½¿ç”¨OpenAIè´¦æˆ·ç±»å‹ã€‚

### æ­¥éª¤ 1: ä¿®æ”¹OpenAIè´¦æˆ·æœåŠ¡

**æ–‡ä»¶:** `src/services/openaiAccountService.js`

åœ¨æ–‡ä»¶ä¸­æ‰¾åˆ°APIè°ƒç”¨éƒ¨åˆ†,æ·»åŠ è‡ªå®šä¹‰base URLæ”¯æŒ:

```javascript
// æ·»åŠ é…ç½®é€‰é¡¹
const CUSTOM_OPENAI_ENDPOINTS = {
  'qwen3-32b': 'http://192.168.1.100:8000/v1',
  'qwen3-235b': 'http://192.168.1.101:8000/v1',
  'glm-4.6': 'http://192.168.1.102:8000/v1'
}

// åœ¨makeOpenAIRequestå‡½æ•°ä¸­ä½¿ç”¨è‡ªå®šä¹‰endpoint
function getOpenAIEndpoint(model) {
  return CUSTOM_OPENAI_ENDPOINTS[model] || 'https://api.openai.com/v1'
}
```

### æ­¥éª¤ 2: é€šè¿‡Webç•Œé¢æ·»åŠ OpenAIè´¦æˆ·

```json
{
  "name": "Qwen3-235B Local",
  "description": "æœ¬åœ°éƒ¨ç½²çš„Qwen3-235B",
  "accountType": "shared",
  "apiKey": "sk-custom-key",
  "supportedModels": ["qwen3-235b", "claude-3-opus-20240229"],
  "priority": 60,
  "isActive": true
}
```

## ğŸ“ å¤šæ¨¡å‹é…ç½®ç¤ºä¾‹

### é…ç½®æ–‡ä»¶: `custom-models-config.json`

```json
{
  "models": [
    {
      "name": "Qwen3-VL-235B",
      "endpoint": "http://192.168.1.100:8000",
      "deployment": "qwen3-vl-235b",
      "type": "vision",
      "mapping": "claude-3-opus-20240229"
    },
    {
      "name": "Qwen3-32B",
      "endpoint": "http://192.168.1.101:8000",
      "deployment": "qwen3-32b",
      "type": "chat",
      "mapping": "claude-3-sonnet-20240229"
    },
    {
      "name": "GLM-4.6-FP8",
      "endpoint": "http://192.168.1.102:8000",
      "deployment": "glm-4.6-fp8",
      "type": "chat",
      "mapping": "claude-3-haiku-20240307"
    },
    {
      "name": "Qwen3-Coder-480B",
      "endpoint": "http://192.168.1.103:8000",
      "deployment": "qwen3-coder-480b",
      "type": "code",
      "mapping": "claude-3-opus-20240229"
    }
  ]
}
```

### æ‰¹é‡å¯¼å…¥è„šæœ¬

åˆ›å»ºè„šæœ¬ `import-custom-models.sh`:

```bash
#!/bin/bash

RELAY_ADMIN_URL="http://localhost:3000/admin"
ADMIN_TOKEN="your-admin-session-token"

# è¯»å–é…ç½®æ–‡ä»¶
cat custom-models-config.json | jq -c '.models[]' | while read model; do
  NAME=$(echo $model | jq -r '.name')
  ENDPOINT=$(echo $model | jq -r '.endpoint')
  DEPLOYMENT=$(echo $model | jq -r '.deployment')
  MAPPING=$(echo $model | jq -r '.mapping')

  echo "Adding model: $NAME"

  curl -X POST "$RELAY_ADMIN_URL/azure-openai-accounts" \
    -H "Content-Type: application/json" \
    -H "Cookie: admin_session=$ADMIN_TOKEN" \
    -d "{
      \"name\": \"$NAME\",
      \"description\": \"Custom deployed model\",
      \"accountType\": \"shared\",
      \"azureEndpoint\": \"$ENDPOINT\",
      \"apiVersion\": \"2024-02-01\",
      \"deploymentName\": \"$DEPLOYMENT\",
      \"apiKey\": \"sk-custom\",
      \"supportedModels\": [\"$MAPPING\"],
      \"priority\": 50,
      \"isActive\": true,
      \"schedulable\": true
    }"

  echo ""
done
```

## ğŸ” å®‰å…¨å»ºè®®

### 1. ä½¿ç”¨è®¤è¯

ä¸ºæ‚¨çš„æ¨¡å‹æœåŠ¡æ·»åŠ API Keyè®¤è¯:

**vLLMç¤ºä¾‹:**
```bash
python -m vllm.entrypoints.openai.api_server \
  --model Qwen/Qwen3-32B \
  --api-key sk-your-secure-key
```

### 2. ä½¿ç”¨åå‘ä»£ç†

é€šè¿‡Nginxæ·»åŠ HTTPSå’Œè®¿é—®æ§åˆ¶:

```nginx
server {
    listen 443 ssl;
    server_name your-model-server.com;

    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;

    location /v1/ {
        proxy_pass http://localhost:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;

        # API KeyéªŒè¯
        if ($http_authorization != "Bearer sk-your-key") {
            return 401;
        }
    }
}
```

### 3. ç½‘ç»œéš”ç¦»

å°†æ¨¡å‹æœåŠ¡å™¨æ”¾åœ¨å†…ç½‘,åªå…è®¸Claude Relay Serviceè®¿é—®:

```bash
# iptablesè§„åˆ™
iptables -A INPUT -p tcp --dport 8000 -s 192.168.1.10 -j ACCEPT
iptables -A INPUT -p tcp --dport 8000 -j DROP
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### æŸ¥çœ‹æ¨¡å‹ä½¿ç”¨æƒ…å†µ

åœ¨Claude Relay Serviceç®¡ç†ç•Œé¢:
1. **Dashboard** - æŸ¥çœ‹æ€»ä½“ä½¿ç”¨ç»Ÿè®¡
2. **API Keys** - æŸ¥çœ‹æ¯ä¸ªå®¢æˆ·ç«¯çš„ä½¿ç”¨é‡
3. **Accounts** - æŸ¥çœ‹æ¯ä¸ªæ¨¡å‹çš„è°ƒç”¨æ¬¡æ•°

### æ¨¡å‹æœåŠ¡å™¨æ—¥å¿—

**vLLMæ—¥å¿—:**
```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f /var/log/vllm/server.log

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
grep ERROR /var/log/vllm/server.log
```

## ğŸš¨ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: è¿æ¥è¶…æ—¶

**æ£€æŸ¥é¡¹:**
- æ¨¡å‹æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ: `curl http://server:port/v1/models`
- é˜²ç«å¢™æ˜¯å¦å¼€æ”¾ç«¯å£: `telnet server port`
- Claude Relay Serviceç½‘ç»œè¿é€šæ€§

### é—®é¢˜ 2: æ¨¡å‹å“åº”æ ¼å¼é”™è¯¯

**è§£å†³æ–¹æ¡ˆ:**
ç¡®ä¿æ¨¡å‹æœåŠ¡è¿”å›OpenAIå…¼å®¹çš„JSONæ ¼å¼:

```json
{
  "id": "chatcmpl-xxx",
  "object": "chat.completion",
  "created": 1234567890,
  "model": "qwen3-32b",
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "å›å¤å†…å®¹"
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 20,
    "total_tokens": 30
  }
}
```

### é—®é¢˜ 3: æ¨¡å‹ä¸è¢«è°ƒåº¦

**æ£€æŸ¥é…ç½®:**
- `isActive`: å¿…é¡»ä¸º `true`
- `schedulable`: å¿…é¡»ä¸º `true`
- `priority`: æ•°å€¼è¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜
- ç¡®è®¤æ¨¡å‹æ˜ å°„åˆ°äº†æ­£ç¡®çš„Claudeæ¨¡å‹åç§°

## ğŸ“š å®¢æˆ·ç«¯é…ç½®

### Claude Codeé…ç½®

ç¼–è¾‘ `~/.config/claude/config.json`:

```json
{
  "api": {
    "baseURL": "http://your-relay-server:3000",
    "apiKey": "cr_your_relay_api_key"
  }
}
```

### å…¶ä»–å®¢æˆ·ç«¯

ä»»ä½•æ”¯æŒClaude APIçš„å®¢æˆ·ç«¯éƒ½å¯ä»¥ä½¿ç”¨:

```python
import anthropic

client = anthropic.Anthropic(
    base_url="http://your-relay-server:3000",
    api_key="cr_your_relay_api_key"
)

response = client.messages.create(
    model="claude-3-opus-20240229",  # æ˜ å°„åˆ°æ‚¨çš„Qwenæ¨¡å‹
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "ä½ å¥½"}
    ]
)

print(response.content[0].text)
```

## ğŸ‰ å®Œæˆ

ç°åœ¨æ‚¨å¯ä»¥é€šè¿‡Claude Relay Serviceç»Ÿä¸€ç®¡ç†å’Œä½¿ç”¨è‡ªéƒ¨ç½²çš„å¼€æºæ¨¡å‹äº†!

**ä¼˜åŠ¿:**
- âœ… ç»Ÿä¸€çš„APIæ¥å£
- âœ… å¤šæ¨¡å‹è‡ªåŠ¨è°ƒåº¦å’Œè´Ÿè½½å‡è¡¡
- âœ… ä½¿ç”¨é‡ç»Ÿè®¡å’Œç›‘æ§
- âœ… API Keyç®¡ç†
- âœ… è®¿é—®æ§åˆ¶å’Œé™æµ

## ğŸ“ éœ€è¦å¸®åŠ©?

é‡åˆ°é—®é¢˜è¯·æŸ¥çœ‹:
- [Claude Relay Serviceæ–‡æ¡£](README.md)
- [å®˜æ–¹GitHub Issues](https://github.com/Wei-Shaw/claude-relay-service/issues)
- [Telegramç¾¤ç»„](https://t.me/claude_relay_service)
